{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "aujtRZKSczZC",
    "outputId": "49185a30-e2a6-44fc-d69e-f897d2254709"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from torch.autograd import grad\n",
    "from torch.nn import Parameter\n",
    "cuda = torch.cuda.is_available()\n",
    "import pickle as pk\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "import fish_models\n",
    "import robofish.io\n",
    "\n",
    "fishes = 2\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfilename = 'model.pth'\n",
    "\n",
    "# Test training\n",
    "n_training_iterations = 10\n",
    "n_files = 1\n",
    "n_timesteps = 1500\n",
    "n_speed_bins = 21\n",
    "n_turn_bins = 21\n",
    "n_view_bins = 5\n",
    "n_timesteps_simulation = 2000\n",
    "\n",
    "\"\"\"\n",
    "# Full training\n",
    "n_training_iterations = 5000\n",
    "n_files = None\n",
    "n_timesteps = None\n",
    "n_speed_bins = 63\n",
    "n_turn_bins = 63\n",
    "n_view_bins = 31\n",
    "n_timesteps_simulation = 10000\n",
    "\"\"\"\n",
    "\n",
    "# IO Files in cm, actions in m/s\n",
    "data_folder = Path(\"data/live_female_female/train\")\n",
    "test_data_folder = Path(\"data/live_female_female/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qajbJVVEJzbX",
    "outputId": "aa6df4ad-cb55-4ea9-bf48-2663a072570a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetBlock(\n",
       "  (conv1): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (relu1): LeakyReLU(negative_slope=0.01)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3): LeakyReLU(negative_slope=0.01)\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(64, 16, kernel_size=(3, 3), stride=(2, 2), padding=(17, 17))\n",
       "  (relu4): LeakyReLU(negative_slope=0.01)\n",
       "  (bn4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (identity_upsample): Sequential(\n",
       "    (0): Conv2d(1, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet uses blocks\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.kernel_size = 3\n",
    "\n",
    "        # structure\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels= 16, kernel_size=self.kernel_size, stride=1, padding=1)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=self.kernel_size, stride=1, padding=1)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=self.kernel_size, stride=1, padding=1)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=16, kernel_size=self.kernel_size, stride=2, padding=(32 - 15))\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.bn4 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # 1x1 conv filters can be used to change the dimensionality in the filter space.\n",
    "        self.identity_upsample = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels * 2, kernel_size=1, stride=1),\n",
    "                                          nn.BatchNorm2d(in_channels * 2))\n",
    "        #self.identity_downsample = nn.Sequential(nn.Conv2d(in_channels=out_channels * 2, out_channels=in_channels, kernel_size=1, stride=1), nn.BatchNorm2d(in_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # we use this block multipy times\n",
    "        # DEBUG\n",
    "        #print(f'x forward start: {x.shape}')\n",
    "\n",
    "        # save first identity\n",
    "        identity1 = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        # sum point\n",
    "        x = x + identity1\n",
    "\n",
    "        # save second identity and change size to be able to summurize in the next sum point\n",
    "        identity_upsampled = self.identity_upsample(x)\n",
    "        # DEBUG\n",
    "        #print(f'identity_upsample : {identity_upsampled.shape}')\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.bn4(x)\n",
    "\n",
    "        # DEBUG\n",
    "        #print(f'x for last sum point: {x.shape}')  \n",
    "\n",
    "        # sum point\n",
    "        x = x + identity_upsampled\n",
    "        return x\n",
    "\n",
    "block = ResNetBlock(in_channels=1, out_channels=1)\n",
    "block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dL9m_NKSORzh"
   },
   "outputs": [],
   "source": [
    "# # 2d: [batch_size, num_features (aka: C * H * W)]\n",
    "# use for nn.Linear() input.\n",
    "\n",
    "class ResNet(nn.Module): \n",
    "    # layers is the list telling us how much to reuse the block in each block\n",
    "    def __init__(self, block, N):\n",
    "        \"\"\"ResNet is a short name for Residual Network.\n",
    "        A deep convolutional neural network, \n",
    "        several layers are stacked and are trained to the task at hand. \n",
    "        The network learns several low/mid/high level features at the end of its layers. \n",
    "        \n",
    "        The main innovation of ResNet is the skip connection. \n",
    "        Deep networks often suffer from vanishing gradients, \n",
    "        ie: as the model backpropagates, the gradient gets smaller and smaller. \n",
    "        \n",
    "        This allows to stack additional layers and build a deeper network.\n",
    "        \n",
    "        Args:\n",
    "            TODO\n",
    "        \"\"\"\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 1\n",
    "        self.kernel_size = 3\n",
    "        self.start_identity = None\n",
    "        self.batch_small = 2\n",
    "        self.N = N\n",
    "\n",
    "        # Begin\n",
    "        self.fc1 = nn.Linear(in_features=2*n_view_bins, out_features=3*n_view_bins)\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels= 16, kernel_size=3, stride = 1, padding = 1)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(1)\n",
    "\n",
    "        # ResNet Layers\n",
    "        # repeat 3 times for i in range(2)\n",
    "        # out_channel is equal to 16 * 2 * i => 16*2^0, 16*2^1, 16*2^2 => 16, 32 and 64 out_channels\n",
    "        self.layer1 = self.make_layer(block, self.N, out_channels=2)\n",
    "        self.layer2 = self.make_layer(block, self.N, out_channels=4)\n",
    "        self.layer3 = self.make_layer(block, self.N, out_channels=8)\n",
    "\n",
    "        # End\n",
    "        self.fc = nn.Linear(in_features=3*n_view_bins, out_features=n_speed_bins + n_turn_bins)\n",
    "        \n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        # Begin\n",
    "        # [batch_size, seq_length] as input data -> add the channel dimension using unsqueeze\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x = self.bn1(x)\n",
    "        x = x.squeeze(1)\n",
    "\n",
    "        # ResNet Layers forward step\n",
    "        # loops inside every layer\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        #print('\\nExit looped structure')\n",
    "\n",
    "        # End\n",
    "        #print(f'\\nafter layers structure: {x.shape}')    \n",
    "        if x.shape[0] == self.batch_size:\n",
    "            x = x.view(self.batch_size, -1)\n",
    "        else:\n",
    "            x = x.view(x.shape[0], -1)\n",
    "        #print(f'\\nafter view(): {x.shape}')\n",
    "\n",
    "        x = self.fc(x)\n",
    "        #print(f'after fc_10: {x.shape}')\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def make_layer(self, block, num_residual_blocks, out_channels):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        print(f'Extern loop START')\n",
    "        layers.append(block(self.in_channels, out_channels))\n",
    "        self.in_channels = out_channels * 2\n",
    "\n",
    "          # intern loops for layers and skip connections\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "            print(f'Inner layer {n} is created!')\n",
    "\n",
    "        print(f'Extern loop END')\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "JT6EkAY--Ltv",
    "outputId": "ba84add5-4a30-4635-9b10-5013b8cce70c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extern loop START\n",
      "Extern loop END\n",
      "Extern loop START\n",
      "Extern loop END\n",
      "Extern loop START\n",
      "Extern loop END\n"
     ]
    }
   ],
   "source": [
    "class ResNetFishModel(fish_models.gym_interface.AbstractModel):\n",
    "    def __init__(self, speed_bins, turn_bins):\n",
    "        self.speed_bins = speed_bins\n",
    "        self.turn_bins = turn_bins\n",
    "        \n",
    "        self.deep_model = ResNet(ResNetBlock, 1)\n",
    "        \n",
    "    def choose_action(self, view: np.ndarray):\n",
    "\n",
    "        #action = self.predict_action(view)\n",
    "        \n",
    "        #returns speed, turn\n",
    "        #return action[0][0], action[0][1]\n",
    "        return 10, 2*np.pi\n",
    "    \n",
    "    def predict_action(self, view: np.ndarray):\n",
    "        pass\n",
    "        #clustermodel.predict([view]) returns the index for list clustermodel.cluster_centers_\n",
    "        #prediction = clustermodel.cluster_centers_[clustermodel.predict([view])][0]\n",
    "        #choice = random.sample(list(clusters[str(prediction)]), 1)\n",
    "        #return choice\n",
    "   \n",
    "\n",
    "    def train(self, dset, test_dset, optimizer, criterion, max_epochs):\n",
    "       \n",
    "        \"\"\"Binarize the binned actions and train the classifier\n",
    "\n",
    "        Args:\n",
    "            dset: An IoDataset with at least output_strings [\"actions_binned\", \"views\"]\n",
    "        \"\"\"\n",
    "\n",
    "        self.poses_storage = []\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "                dset,\n",
    "                collate_fn=fish_models.datasets.io_dataset.IODatasetPytorchDataloaderCollateFN(\n",
    "                    [\"views\", \"actions_binned\"], [torch.float64, torch.long]\n",
    "                ),\n",
    "                batch_size = 64\n",
    "            )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "                test_dset,\n",
    "                collate_fn=fish_models.datasets.io_dataset.IODatasetPytorchDataloaderCollateFN(\n",
    "                    [\"views\", \"actions_binned\"], [torch.float64, torch.long]\n",
    "                ),\n",
    "                batch_size = 16\n",
    "            )\n",
    "        \n",
    "        \n",
    "        mean_losses = []\n",
    "        \n",
    "        batch_total = len(train_loader)\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            samples_total = 0\n",
    "            samples_correct = 0\n",
    "            test_samples_total = 0\n",
    "            test_samples_correct = 0\n",
    "            for batch_idx,batch in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                x, y = batch\n",
    "\n",
    "                if cuda:\n",
    "                    x, y = x.cuda(),y.cuda()\n",
    "\n",
    "                output = model.deep_model(x)\n",
    "                loss = criterion(output[:,:n_speed_bins], y[:,0]) + criterion(output[:,n_speed_bins:], y[:,1])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                yhat1 = torch.argmax(output[:,:n_speed_bins], dim = 1)\n",
    "                yhat2 = torch.argmax(output[:,n_speed_bins:], dim = 1)\n",
    "                samples_total = 2*len(y)\n",
    "                samples_correct += torch.sum(yhat1 == y[:,0])\n",
    "                samples_correct += torch.sum(yhat2 == y[:,1])\n",
    "\n",
    "                losses.append(loss.item())\n",
    "                mean_losses.append(np.mean(losses))\n",
    "                \n",
    "                if batch_idx % 50 == 0:\n",
    "                    acc = float(samples_correct)/float(samples_total)\n",
    "                    \n",
    "                sys.stdout.write(f'\\rEpoch: {epoch:2}/{max_epochs:2} Step: {batch_idx:2}/{batch_total:2} Loss: {loss.item():10.6f} ')\n",
    "\n",
    "            checkpoint = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'losses': losses\n",
    "            }\n",
    "            self.savemodel(checkpoint)\n",
    "        \n",
    "        print('\\nFinished Training')\n",
    "\n",
    "        return losses, mean_losses\n",
    "    \n",
    "    def savemodel(self,checkpoint):    \n",
    "        checkpoint_path = os.path.join(modelfilename)\n",
    "        with open(checkpoint_path, 'wb') as f:\n",
    "            pk.dump(checkpoint, f)\n",
    "\n",
    "\n",
    "\"\"\" Find the 0.5% percentile and 99.5% percentile of the data to set the bins. \"\"\"\n",
    "\n",
    "# Create the bins. The values come from the quantiles and testing.\n",
    "speed_bins = np.linspace(-2, 20, n_speed_bins)\n",
    "turn_bins = np.linspace(-10, 10, n_turn_bins)\n",
    "\n",
    "# ! CREATE MODEL !\n",
    "\n",
    "model = ResNetFishModel(speed_bins, turn_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RG3tZv6T-M00"
   },
   "outputs": [],
   "source": [
    "raycast = fish_models.gym_interface.Raycast(\n",
    "            n_wall_raycasts=n_view_bins,\n",
    "            n_fish_bins=n_view_bins,\n",
    "            fov_angle_fish_bins= 2 * np.pi,\n",
    "            fov_angle_wall_raycasts=2 * np.pi,\n",
    "            world_bounds=([-50, -50], [50, 50]),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from 1 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1500, 2)\n",
      "(2, 1500, 3)\n",
      "Calculating views from 1 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of IoDataset:\n",
      "The first 3 dimensions are reduced from (1, 2, 1500) to (3000)\n",
      "actions\t(3000, 2):\tconsisting of speed [cm/s] and turn [rad/s].\n",
      "actions_binned\t(3000, 2):\tconsisting of speed [discretized into 20 bins] and turn [discretized into 20 bins]\n",
      "views\t(3000, 10):\t5 fish_bins and 5 wall ray casts.\n",
      "\n",
      "Loading data from 1 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.58s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1500, 2)\n",
      "(2, 1500, 3)\n",
      "Calculating views from 1 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of IoDataset:\n",
      "The first 3 dimensions are reduced from (1, 2, 1500) to (3000)\n",
      "actions\t(3000, 2):\tconsisting of speed [cm/s] and turn [rad/s].\n",
      "actions_binned\t(3000, 2):\tconsisting of speed [discretized into 20 bins] and turn [discretized into 20 bins]\n",
      "views\t(3000, 10):\t5 fish_bins and 5 wall ray casts.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset. When using actions_binned, the borders are neccessary.\n",
    "dset = fish_models.datasets.io_dataset.IoDataset(\n",
    "    data_folder,\n",
    "    raycast,\n",
    "    output_strings=[\"actions\", \"actions_binned\", \"views\"],\n",
    "    reduce_dim=2,\n",
    "    max_files=n_files,\n",
    "    max_timesteps=n_timesteps,\n",
    "    speed_bin_borders=speed_bins,\n",
    "    turn_bin_borders=turn_bins,\n",
    ")\n",
    "test_dset = fish_models.datasets.io_dataset.IoDataset(\n",
    "    test_data_folder,\n",
    "    raycast,\n",
    "    output_strings=[\"actions\", \"actions_binned\", \"views\"],\n",
    "    reduce_dim=2,\n",
    "    max_files=n_files,\n",
    "    max_timesteps=n_timesteps,\n",
    "    speed_bin_borders=speed_bins,\n",
    "    turn_bin_borders=turn_bins,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.deep_model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 1, 3], expected input[64, 16, 10] to have 1 channels, but got 16 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-88b13847e6c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nTraining took {end - start}s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-af0475447d2c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dset, test_dset, optimizer, criterion, max_epochs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_speed_bins\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_speed_bins\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Robofish-IwTRahcW/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7f742e697acc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# ResNet Layers forward step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# loops inside every layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Robofish-IwTRahcW/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Robofish-IwTRahcW/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Robofish-IwTRahcW/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-30f02ab2b5ef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0midentity1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Robofish-IwTRahcW/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Robofish-IwTRahcW/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Robofish-IwTRahcW/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    292\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 294\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    295\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 1, 3], expected input[64, 16, 10] to have 1 channels, but got 16 channels instead"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.train(dset, test_dset, optimizer, criterion, max_epochs=1)\n",
    "end = time.time()\n",
    "print(f'\\nTraining took {end - start}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ResNetFischModel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
