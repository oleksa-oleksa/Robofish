{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "aujtRZKSczZC",
    "outputId": "49185a30-e2a6-44fc-d69e-f897d2254709"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from torch.autograd import grad\n",
    "from torch.nn import Parameter\n",
    "cuda = torch.cuda.is_available()\n",
    "import pickle as pk\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "import fish_models\n",
    "import robofish.io\n",
    "\n",
    "fishes = 4\n",
    "in_channels_global = 1\n",
    "out_channels_global = 1\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qajbJVVEJzbX",
    "outputId": "aa6df4ad-cb55-4ea9-bf48-2663a072570a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetBlock(\n",
       "  (conv1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1): LeakyReLU(negative_slope=0.01)\n",
       "  (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3): LeakyReLU(negative_slope=0.01)\n",
       "  (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(1, 2, kernel_size=(3, 3), stride=(2, 2), padding=(17, 17))\n",
       "  (relu4): LeakyReLU(negative_slope=0.01)\n",
       "  (bn4): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (identity_upsample): Sequential(\n",
       "    (0): Conv2d(1, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet uses blocks\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.kernel_size = 3\n",
    "\n",
    "        # structure\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=self.kernel_size, stride=1, padding=1)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=self.kernel_size, stride=1, padding=1)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv3 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=self.kernel_size, stride=1, padding=1)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv4 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels * 2, kernel_size=self.kernel_size, stride=2, padding=(32 - 15))\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.bn4 = nn.BatchNorm2d(in_channels * 2)\n",
    "\n",
    "        # 1x1 conv filters can be used to change the dimensionality in the filter space.\n",
    "        self.identity_upsample = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels * 2, kernel_size=1, stride=1),\n",
    "                                          nn.BatchNorm2d(in_channels * 2))\n",
    "        #self.identity_downsample = nn.Sequential(nn.Conv2d(in_channels=out_channels * 2, out_channels=in_channels, kernel_size=1, stride=1), nn.BatchNorm2d(in_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # we use this block multipy times\n",
    "        # DEBUG\n",
    "        #print(f'x forward start: {x.shape}')\n",
    "\n",
    "        # save first identity\n",
    "        identity1 = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        # sum point\n",
    "        x = x + identity1\n",
    "\n",
    "        # save second identity and change size to be able to summurize in the next sum point\n",
    "        identity_upsampled = self.identity_upsample(x)\n",
    "        # DEBUG\n",
    "        #print(f'identity_upsample : {identity_upsampled.shape}')\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.bn4(x)\n",
    "\n",
    "        # DEBUG\n",
    "        #print(f'x for last sum point: {x.shape}')  \n",
    "\n",
    "        # sum point\n",
    "        x = x + identity_upsampled\n",
    "        return x\n",
    "\n",
    "block = ResNetBlock(in_channels=in_channels_global, out_channels=out_channels_global)\n",
    "block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "dL9m_NKSORzh"
   },
   "outputs": [],
   "source": [
    "# # 2d: [batch_size, num_features (aka: C * H * W)]\n",
    "# use for nn.Linear() input.\n",
    "\n",
    "class ResNet(nn.Module): \n",
    "    # layers is the list telling us how much to reuse the block in each block\n",
    "    def __init__(self, block, N, image_channel, num_classes, batch_size=64):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = in_channels_global\n",
    "        self.kernel_size = 3\n",
    "        self.start_identity = None\n",
    "        self.linear_size = 808920\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_small = 2\n",
    "        self.N = N\n",
    "\n",
    "        # Begin\n",
    "        self.conv1 = nn.Conv2d(in_channels=image_channel, out_channels=1, kernel_size=self.kernel_size, stride=1, padding=1)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(1)\n",
    "\n",
    "        # ResNet Layers\n",
    "        # repeat 3 times for i in range(2)\n",
    "        # out_channel is equal to 16 * 2 * i => 16*2^0, 16*2^1, 16*2^2 => 16, 32 and 64 out_channels\n",
    "        self.layer1 = self.make_layer(block, self.N, out_channels=2)\n",
    "        self.layer2 = self.make_layer(block, self.N, out_channels=4)\n",
    "        self.layer3 = self.make_layer(block, self.N, out_channels=8)\n",
    "\n",
    "        # End\n",
    "        self.fc_10 = nn.Linear(in_features=self.linear_size, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        # Begin \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        # ResNet Layers forward step\n",
    "        # loops inside every layer\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        #print('\\nExit looped structure')\n",
    "\n",
    "        # End\n",
    "        #print(f'\\nafter layers structure: {x.shape}')    \n",
    "        if x.shape[0] == self.batch_size:\n",
    "            x = x.view(self.batch_size, -1)\n",
    "        else:\n",
    "            x = x.view(x.shape[0], -1)\n",
    "        #print(f'\\nafter view(): {x.shape}')\n",
    "\n",
    "        x = self.fc_10(x)\n",
    "        #print(f'after fc_10: {x.shape}')\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def make_layer(self, block, num_residual_blocks, out_channels):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        print(f'Extern loop START')\n",
    "        layers.append(block(self.in_channels, out_channels))\n",
    "        self.in_channels = out_channels * 2\n",
    "\n",
    "          # intern loops for layers and skip connections\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "            print(f'Inner layer {n} is created!')\n",
    "\n",
    "        print(f'Extern loop END')\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "JT6EkAY--Ltv",
    "outputId": "ba84add5-4a30-4635-9b10-5013b8cce70c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extern loop START\n",
      "Extern loop END\n",
      "Extern loop START\n",
      "Extern loop END\n",
      "Extern loop START\n",
      "Extern loop END\n"
     ]
    }
   ],
   "source": [
    "class ResNetFishModel(fish_models.gym_interface.AbstractRaycastBasedModel):\n",
    "    def __init__(self):\n",
    "        self.deep_model = ResNet(ResNetBlock, 1, image_channel=in_channels_global, num_classes=out_channels_global, batch_size=64)\n",
    "        \n",
    "    def choose_action(self, view: np.ndarray):\n",
    "\n",
    "        #action = self.predict_action(view)\n",
    "        \n",
    "        #returns speed, turn\n",
    "        #return action[0][0], action[0][1]\n",
    "        return 10, 2*np.pi\n",
    "    \n",
    "    def predict_action(self, view: np.ndarray):\n",
    "        pass\n",
    "        #clustermodel.predict([view]) returns the index for list clustermodel.cluster_centers_\n",
    "        #prediction = clustermodel.cluster_centers_[clustermodel.predict([view])][0]\n",
    "        #choice = random.sample(list(clusters[str(prediction)]), 1)\n",
    "        #return choice\n",
    "   \n",
    "\n",
    "    def train(self, dset, optimizer, criterion, max_epoch):\n",
    "       \n",
    "        inputs = torch.from_numpy(dset[:][\"views\"])\n",
    "        labels = torch.from_numpy(dset[:][\"actions\"])\n",
    "        losses = []\n",
    "        batch_total = len(inputs)\n",
    "        \n",
    "        for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "            samples_total = 0\n",
    "            samples_correct = 0\n",
    "            samples_correct_test = 0\n",
    "\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for i in inputs:\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                output = self.deep_model(inputs)\n",
    "\n",
    "                # DEBUG\n",
    "                #print(f'Input shape: {inputs.shape}')\n",
    "                #print(f'Output shape: {output.shape}')\n",
    "                #print(f'Labels: {labels}')\n",
    "                #print(f'Labels shape: {labels.shape}')\n",
    "                #print(f'\\nIndex: {batch_idx}, len of batch: {len(batch[0])}')\n",
    "\n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                yhat = torch.argmax(output, dim=1)\n",
    "\n",
    "                samples_total += len(labels)\n",
    "                samples_correct += torch.sum(yhat == labels)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                # print statistics\n",
    "                if i % 50 == 0:\n",
    "                    acc = float(samples_correct) / float(samples_total)\n",
    "\n",
    "                    sys.stdout.write(f'\\repoch: {epoch} / {max_epoch} Step: {i}/{batch_total}, Loss: {loss.item():.6f}, Acc: {acc:.2%}')\n",
    "\n",
    "        print('\\nFinished Training')\n",
    "        return losses\n",
    "            \n",
    "    \n",
    "model = ResNetFishModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "RG3tZv6T-M00"
   },
   "outputs": [],
   "source": [
    "raycast = fish_models.gym_interface.Raycast(\n",
    "            n_wall_raycasts=5,\n",
    "            n_fish_bins=4,\n",
    "            fov_angle_fish_bins=np.pi,\n",
    "            fov_angle_wall_raycasts=np.pi,\n",
    "            world_bounds=([-50, -50], [50, 50]),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from 1 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating views from 1 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created IoDataset:\n",
      "Reduced the first 3 dimensions from (1, 2, 8989) to (17978)\n",
      "poses\t(17978, 3):\tconsisting of x, y, calc_ori_rad.\n",
      "actions\t(17976, 2):\tconsisting of speed[cm/s] and turn [rad/s].\n",
      "views\t(17976, 9):\t4 fish_bins and 5 wall ray casts.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_folder = Path(\"data/live_female_female/train\")\n",
    "\n",
    "dset = fish_models.datasets.io_dataset.IoDataset(\n",
    "    data_folder,\n",
    "    raycast,\n",
    "    output_strings=[\"poses\", \"actions\", \"views\"],\n",
    "    reduce_dim=2,\n",
    "    max_files=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.deep_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [1, 9, 3, 3], but got 2-dimensional input of size [17976, 9] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ccbb4a14dfae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nTraining took {end - start}s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-a4dc196743f7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dset, optimizer, criterion, max_epoch)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;31m# DEBUG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Robofish-IwTRahcW/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-c14bba225abb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Begin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Robofish-IwTRahcW/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Robofish-IwTRahcW/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Robofish-IwTRahcW/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 395\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    396\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [1, 9, 3, 3], but got 2-dimensional input of size [17976, 9] instead"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "losses = model.train(dset, optimizer, criterion, max_epoch=1)\n",
    "end = time.time()\n",
    "print(f'\\nTraining took {end - start}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ResNetFischModel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
